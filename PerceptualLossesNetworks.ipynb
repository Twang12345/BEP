{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptual Losses Networks\n",
    "### This script applies to\n",
    "                - Original Perceptual Loss Network, \n",
    "                - Width-Concatenated Perceptual Losses Network,                         \n",
    "                - Channel-Concatenated Perceptual Losses Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import *\n",
    "import fastai\n",
    "from fastai.callbacks import *\n",
    "from fastai.vision.gan import *\n",
    "from fastai.vision.learner import cnn_config\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.models import vgg16_bn\n",
    "from torchvision.models import vgg19_bn\n",
    "from torchvision.models import densenet201\n",
    "from matplotlib.pyplot import *\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathroot = Path('/storage/BEP')\n",
    "path = pathroot/'data2'\n",
    "path_low = path/'low_count/'\n",
    "path_high = path/'high_count/'\n",
    "path_tests = pathroot/'tests2'\n",
    "path_predictions = pathroot/'Predictions_50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the DataLoaders Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining batch size and dimensions of training images\n",
    "bs,size=8,512 #Size for width concatenation equals 3*512 = 1536\n",
    "\n",
    "#Progressive resizing: First decreasing image size (which enables higher batch size)\n",
    "bs,size=bs*2,size//2\n",
    "\n",
    "#Defining the ResNet34 architecture to be used as the decoding part of the U-Net learner\n",
    "arch = models.resnet34\n",
    "\n",
    "#Defining the low-count image list and splitting of a portion of 10 procent to be used as validation\n",
    "src = ImageImageList.from_folder(path_low).split_by_rand_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function that returns the correct path of the high-count image to its corresponding low-count image\n",
    "def correct_path(path_in, path_high):\n",
    "    y = str(path_in).split('/')\n",
    "    return Path(str(path_high) + '/' + y[-2]+ '/'+ y[-1])\n",
    "\n",
    "#Defining a function that finally creates the dataloader object that will be passed to the U-Net learner\n",
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: correct_path(x, path_high))\n",
    "           .transform(get_transforms(max_zoom=2.,max_rotate=15), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs, num_workers=0))\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executing our earlier defined function to create the dataloaders object\n",
    "data = get_data(bs,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the VGG-19 Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_m = vgg19_bn(True).features.cuda().eval()\n",
    "requires_grad(loss_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(loss_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "base_loss = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(loss_m, blocks[2:5], [5,15,2]).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dynamic U-Net learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the initial weight decay\n",
    "wd = 1e-3\n",
    "\n",
    "#Initiasing the U-Net learner by passing it our data and decoder architecture\n",
    "learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics,\n",
    "                     blur=True, self_attention=True, norm_type=NormType.Weight)\n",
    "#Use half-precision\n",
    "learn.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the right learn rate by plotting the loss vs learning rate and looking at where the plot is steepest and using \n",
    "# the corresponding learn rate\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function that trains the network using fit_one_cycle. \n",
    "# Callbacks are used to save the network every trained epoch since the notebook shuts down after 6 hours.\n",
    "# Note that the save destination of the callbacks is defined for my storage: /storage/BEP.\n",
    "lr = 1e-4\n",
    "def do_fit(save_name, no_of_cycles, lrs=slice(lr), pct_start=0.9):\n",
    "    learn.fit_one_cycle(no_of_cycles, lrs, pct_start=pct_start, callbacks=[SaveModelCallback(learn, every='epoch',  \n",
    "                name=f'/storage/BEP/{save_name}_saved_net')])\n",
    "    learn.save(f'/storage/BEP/{save_name}')\n",
    "    learn.show_results(rows=1, imgsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit four 10 epochs\n",
    "do_fit('PLN_Original_1a', 10, slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze the lowest layers\n",
    "learn.unfreeze()\n",
    "do_fit('PLN_Original_1b', 10, slice(1e-5,lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase image size to 512x512, decrease batch size to keep GPU memory usage down\n",
    "# Again setting half-precision and freezing the lowest layers\n",
    "data = get_data(bs//4,size*2)\n",
    "learn.to_fp16();\n",
    "learn.freeze();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fit('PLN_Original_2a', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreezing and using different learn rates for lowest layers and higher learn rate for deepest layers\n",
    "learn.unfreeze()\n",
    "do_fit('PLN_Expanded_2b', 10, slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "do_fit('PLN_Expanded_2c', 10, slice(1e-6,1e-4), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved network\n",
    "learn.load(pathroot/'Models/PLN_Original_2c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again creating the dataloaders object to use for predictions, this time using full-precision\n",
    "data = get_data(bs//4,size*2)\n",
    "learn.to_fp32();\n",
    "learn.freeze();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that retrieves the correct name of current image\n",
    "def name(data,i):\n",
    "    return str(data.items[i]).split('/')[-1]\n",
    "\n",
    "def save_predics(test_set):\n",
    "    #Creating an imagelist to predict from\n",
    "    src_test = ImageImageList.from_folder(path_tests/test_set).split_none()\n",
    "    data_test = src_test.label_from_func(lambda x: path_tests/test_set/x.name)\n",
    "    \n",
    "    #Making directory\n",
    "    os.mkdir(path_predictions/test_set)\n",
    "    \n",
    "    #Predicting and saving the result\n",
    "    for i in range(0,len(data_test.items)):\n",
    "        image = learn.predict(data_test.x[i])[0]\n",
    "        image.save(path_predictions/test_set/name(data_test,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Executing the save_predics function\n",
    "save_predics('test_uniform_new_phantom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip the predictions to be able to download from paperspace storage\n",
    "# Note that the part before .tar is the zip-file name and the second part is which files to zip\n",
    "!tar cvfz PLN_50_predictions.tar.gz /storage/BEP/Predictions_50/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
